{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Math Error Detection Datasets - Download Guide\n\nThis notebook provides step-by-step instructions for downloading and setting up three key datasets for math error detection research:\n\n1. **Math Misconceptions (MaE) Dataset** - 220 algebra misconception examples across 55 misconceptions\n2. **FERMAT Dataset** - 2,244 handwritten math problems with images\n3. **EGE Math Dataset** - 122 Russian EGE exam solutions with 3 image types\n\nEach dataset is useful for different aspects of math error detection and OCR research."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install datasets requests pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Directory Structure\n",
    "\n",
    "Create organized folder structure for all datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create directory structure\nbase_dir = Path(\"math_datasets\")\nprocessed_dir = base_dir / \"processed\"\n\n# Create only the directories we actually use\nfor dir_path in [processed_dir]:\n    dir_path.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Created directory structure:\")\nprint(f\"{base_dir}/\")\nprint(f\"└── processed/    # Clean, ready-to-use datasets\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Dataset 1: Math Misconceptions (MaE) Dataset\n\n**Source**: [HuggingFace - nanote/algebra_misconceptions](https://huggingface.co/datasets/nanote/algebra_misconceptions)  \n**Repository**: [GitHub - nancyotero-projects/math-misconceptions](https://github.com/nancyotero-projects/math-misconceptions)  \n**Paper**: \"A Benchmark for Math Misconceptions: Bridging Gaps in Middle School Algebra with AI-Supported Instruction\" ([arXiv:2412.03765v1](https://arxiv.org/pdf/2412.03765v1))  \n**Size**: 220 examples covering 55 common algebra misconceptions  \n**Language**: English  \n**Content**: Diagnostic examples designed by math learning researchers for middle school algebra  \n**Use Cases**: Testing error detection on specific misconceptions, understanding common student mistakes\n\n## Download Math Misconceptions Dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def download_math_misconceptions():\n    \"\"\"Download math misconceptions dataset from GitHub repository.\"\"\"\n    \n    print(\"Downloading Math Misconceptions (MaE) Dataset...\")\n    \n    try:\n        # Download from GitHub repository\n        github_url = \"https://raw.githubusercontent.com/nancyotero-projects/math-misconceptions/main/data/data.json\"\n        \n        print(\"Downloading from GitHub repository...\")\n        response = requests.get(github_url)\n        \n        if response.status_code != 200:\n            print(f\"Failed to download: HTTP {response.status_code}\")\n            return None\n            \n        data = response.json()\n        print(f\"Successfully downloaded {len(data)} items\")\n        \n        # Create output directories\n        misconceptions_dir = processed_dir / \"math_misconceptions\"\n        misconceptions_dir.mkdir(exist_ok=True)\n        \n        # Process and standardize the data\n        processed_data = []\n        for idx, item in enumerate(data):\n            processed_item = {\n                'index': idx,\n                'question': item.get('Question', ''),\n                'incorrect_answer': item.get('Incorrect Answer', ''),\n                'correct_answer': item.get('Correct Answer', ''),\n                'misconception': item.get('Misconception', ''),\n                'misconception_id': item.get('Misconception ID', ''),\n                'topic': item.get('Topic', ''),\n                'example_number': item.get('Example Number', idx + 1),\n                'dataset': 'math_misconceptions',\n                'language': 'english'\n            }\n            processed_data.append(processed_item)\n        \n        # Save the dataset\n        output_file = misconceptions_dir / \"math_misconceptions.json\"\n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(processed_data, f, indent=2, ensure_ascii=False)\n        \n        # Create dataset info\n        topics = Counter([item.get('topic', 'unknown') for item in processed_data])\n        misconceptions_count = len(set([item.get('misconception_id', '') for item in processed_data if item.get('misconception_id')]))\n        \n        dataset_info = {\n            \"dataset_name\": \"Math Misconceptions (MaE) Dataset\",\n            \"source_url\": \"https://github.com/nancyotero-projects/math-misconceptions\",\n            \"data_url\": \"https://raw.githubusercontent.com/nancyotero-projects/math-misconceptions/main/data/data.json\",\n            \"paper_url\": \"https://arxiv.org/pdf/2412.03765v1\",\n            \"description\": \"Collection of 220 diagnostic examples representing 55 common algebra misconceptions among middle school students\",\n            \"language\": \"English\", \n            \"total_examples\": len(processed_data),\n            \"total_misconceptions\": misconceptions_count,\n            \"topics\": dict(topics.most_common()),\n            \"format\": {\n                \"question\": \"Math problem statement\",\n                \"incorrect_answer\": \"Common student mistake\",\n                \"correct_answer\": \"Expected correct response\", \n                \"misconception\": \"Description of the underlying misconception\",\n                \"misconception_id\": \"Unique identifier for misconception type\",\n                \"topic\": \"Mathematical topic area\",\n                \"example_number\": \"Example number within misconception group\"\n            },\n            \"use_cases\": [\n                \"Testing error detection algorithms on specific misconceptions\",\n                \"Understanding common student mistakes in algebra\", \n                \"Training misconception identification models\",\n                \"Educational research on middle school algebra\"\n            ]\n        }\n        \n        with open(misconceptions_dir / \"dataset_info.json\", 'w', encoding='utf-8') as f:\n            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n        \n        print(f\"Math Misconceptions downloaded: {len(processed_data)} examples\")\n        print(f\"Covers {misconceptions_count} unique misconceptions\")\n        print(f\"Saved to: {output_file}\")\n        \n        return processed_data\n        \n    except Exception as e:\n        print(f\"Error downloading misconceptions: {e}\")\n        print(\"Manual download instructions:\")\n        print(\"1. Visit: https://github.com/nancyotero-projects/math-misconceptions\")\n        print(\"2. Download the data/data.json file\")\n        print(\"3. Save it to the math_misconceptions folder\")\n        return None\n\n# Download the dataset\nmisconceptions_data = download_math_misconceptions()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2: FERMAT Dataset\n",
    "\n",
    "**Source**: [HuggingFace - ai4bharat/fermat](https://huggingface.co/datasets/ai4bharat/fermat)  \n",
    "**Paper**: \"Can Vision-Language Models Evaluate Handwritten Math?\" (arXiv:2501.07244)  \n",
    "**Size**: 2,244 handwritten math problems  \n",
    "**Language**: English  \n",
    "**Content**: Handwritten math solutions with error annotations and images  \n",
    "**Use Cases**: Testing complete OCR + error detection pipeline\n",
    "\n",
    "## Download FERMAT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def download_fermat_dataset(sample_size=100, save_images=True):\n    \"\"\"Download FERMAT dataset from HuggingFace.\n    \n    Args:\n        sample_size: Number of examples to process (default 100, set to None for all 2244)\n        save_images: Whether to save the handwritten images\n    \"\"\"\n    \n    print(f\"Downloading FERMAT Dataset (sample_size: {sample_size})...\")\n    \n    try:\n        # Load dataset from HuggingFace\n        print(\"Loading from HuggingFace...\")\n        dataset = load_dataset(\"ai4bharat/fermat\")\n        train_data = dataset['train']\n        \n        print(f\"Total examples available: {len(train_data)}\")\n        \n        # Create output directories\n        fermat_dir = processed_dir / \"fermat\"\n        fermat_images_dir = fermat_dir / \"images\"\n        fermat_dir.mkdir(exist_ok=True)\n        \n        if save_images:\n            fermat_images_dir.mkdir(exist_ok=True)\n        \n        # Process examples\n        processed_data = []\n        num_to_process = sample_size if sample_size else len(train_data)\n        \n        for idx in range(min(num_to_process, len(train_data))):\n            item = train_data[idx]\n            \n            if idx % 50 == 0:\n                print(f\"Processing example {idx + 1}/{num_to_process}...\")\n            \n            # Extract metadata using correct field names\n            processed_item = {\n                'index': idx,\n                'problem': item.get('orig_q', ''),\n                'correct_answer': item.get('orig_a', ''),\n                'student_answer': item.get('pert_a', ''),\n                'has_error': item.get('has_error', False),\n                'error_reasoning': item.get('pert_reasoning', ''),\n                'domain': item.get('domain_code', ''),\n                'subdomain': item.get('subdomain_code', ''),\n                'grade': item.get('grade', ''),\n                'handwriting_legible': not item.get('handwriting_style', False),  # inverted logic\n                'good_image_quality': not item.get('image_quality', False),  # inverted logic\n                'custom_id': item.get('new_custom_id', ''),\n                'annotation_id': item.get('annot_id', ''),\n                'image_id': item.get('img_id', ''),\n                'perturbation_id': item.get('new_pert_id', ''),\n                'dataset': 'fermat',\n                'language': 'english'\n            }\n            \n            # Handle image\n            if save_images and 'image' in item and item['image']:\n                image_filename = f\"fermat_{idx:04d}.png\"\n                image_path = fermat_images_dir / image_filename\n                \n                try:\n                    # Save PIL Image\n                    item['image'].save(image_path, 'PNG')\n                    processed_item['image_filename'] = image_filename\n                    processed_item['has_image'] = True\n                except Exception as e:\n                    print(f\"Failed to save image {idx}: {e}\")\n                    processed_item['has_image'] = False\n            else:\n                processed_item['has_image'] = False\n            \n            processed_data.append(processed_item)\n        \n        # Save processed dataset\n        output_file = fermat_dir / \"fermat_processed.json\"\n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(processed_data, f, indent=2, ensure_ascii=False)\n        \n        # Create dataset info\n        error_count = sum(1 for item in processed_data if item.get('has_error', False))\n        domains = Counter([item.get('domain', 'unknown') for item in processed_data])\n        grades = Counter([item.get('grade', 'unknown') for item in processed_data])\n        \n        dataset_info = {\n            \"dataset_name\": \"FERMAT: Can Vision-Language Models Evaluate Handwritten Math?\",\n            \"source_url\": \"https://huggingface.co/datasets/ai4bharat/fermat\",\n            \"paper_url\": \"https://arxiv.org/abs/2501.07244\",\n            \"description\": \"Benchmark for assessing VLMs' ability to detect, localize and correct errors in handwritten mathematical content\",\n            \"language\": \"English\",\n            \"total_examples_available\": len(train_data),\n            \"processed_examples\": len(processed_data),\n            \"examples_with_errors\": error_count,\n            \"examples_without_errors\": len(processed_data) - error_count,\n            \"domains\": dict(domains.most_common()),\n            \"grade_distribution\": dict(grades.most_common()),\n            \"field_mapping\": {\n                \"problem\": \"Original math question (from orig_q)\",\n                \"correct_answer\": \"Original correct solution (from orig_a)\",\n                \"student_answer\": \"Perturbed/modified solution (from pert_a)\",\n                \"has_error\": \"Boolean indicating if perturbation introduces actual error\",\n                \"error_reasoning\": \"Explanation of perturbation (from pert_reasoning)\",\n                \"domain\": \"Mathematical domain code (from domain_code)\",\n                \"subdomain\": \"Mathematical subdomain code (from subdomain_code)\",\n                \"grade\": \"Grade level code\",\n                \"image_filename\": \"Corresponding handwritten image file\"\n            },\n            \"format\": {\n                \"problem\": \"Original math question in LaTeX/text\",\n                \"correct_answer\": \"Correct solution in LaTeX\",\n                \"student_answer\": \"Perturbed solution in LaTeX (may contain errors)\",\n                \"has_error\": \"Boolean indicating actual error vs superficial change\",\n                \"error_reasoning\": \"Explanation of introduced perturbation/error\",\n                \"domain\": \"Mathematical domain code (e.g., 'alg' for algebra)\",\n                \"subdomain\": \"Subdomain code (e.g., 'leq' for linear equations)\",\n                \"grade\": \"Grade level (e.g., 'c07' for class 7)\",\n                \"image_filename\": \"Corresponding handwritten image file\"\n            },\n            \"use_cases\": [\n                \"Testing OCR accuracy on handwritten math\",\n                \"Evaluating VLM error detection capabilities\",\n                \"Training handwritten math recognition models\",\n                \"Studying mathematical perturbations and errors\"\n            ]\n        }\n        \n        with open(fermat_dir / \"dataset_info.json\", 'w', encoding='utf-8') as f:\n            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n        \n        print(f\"FERMAT downloaded: {len(processed_data)} examples\")\n        print(f\"Saved to: {output_file}\")\n        if save_images:\n            image_count = sum(1 for item in processed_data if item.get('has_image', False))\n            print(f\"Images saved: {image_count} in {fermat_images_dir}\")\n        \n        # Show sample of what was extracted\n        if len(processed_data) > 0:\n            sample = processed_data[0]\n            print(f\"\\nSample extracted data:\")\n            print(f\"Problem: {sample['problem'][:100]}...\")\n            print(f\"Correct Answer: {sample['correct_answer'][:100]}...\")\n            print(f\"Student Answer: {sample['student_answer'][:100]}...\")\n            print(f\"Has Error: {sample['has_error']}\")\n        \n        return processed_data\n        \n    except Exception as e:\n        print(f\"Error downloading FERMAT: {e}\")\n        return None\n\n# Download the dataset (start with smaller sample)\nfermat_data = download_fermat_dataset(sample_size=100, save_images=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase FERMAT Sample Size (Optional)\n",
    "\n",
    "If you want to download more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download more examples (this may take longer)\n",
    "# fermat_data_large = download_fermat_dataset(sample_size=500, save_images=True)\n",
    "\n",
    "# Uncomment to download ALL examples (this will take significant time and space)\n",
    "# fermat_data_full = download_fermat_dataset(sample_size=None, save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 3: EGE Math Solutions Assessment Benchmark\n",
    "\n",
    "**Source**: [HuggingFace - Karifannaa/EGE_Math_Solutions_Assessment_Benchmark](https://huggingface.co/datasets/Karifannaa/EGE_Math_Solutions_Assessment_Benchmark)  \n",
    "**Paper**: \"EGE Math Solutions Assessment Benchmark\" (arXiv:2507.22958)  \n",
    "**Size**: 122 examples  \n",
    "**Language**: Russian  \n",
    "**Content**: Russian EGE exam solutions with 3 types of images  \n",
    "**Use Cases**: Cross-language error detection, Russian math education research\n",
    "\n",
    "## Download EGE Dataset with All Image Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ege_dataset():\n",
    "    \"\"\"Download EGE Math dataset with all three image types.\"\"\"\n",
    "    \n",
    "    print(\"Downloading EGE Math Dataset...\")\n",
    "    print(\"This dataset contains THREE types of images:\")\n",
    "    print(\"1. images_with_answer (student solutions)\")\n",
    "    print(\"2. images_without_answer (problem statements)\")\n",
    "    print(\"3. images_with_true_solution (correct solutions)\")\n",
    "    \n",
    "    try:\n",
    "        # Load dataset from HuggingFace\n",
    "        dataset = load_dataset(\"Karifannaa/EGE_Math_Solutions_Assessment_Benchmark\")\n",
    "        train_data = dataset['train']\n",
    "        \n",
    "        print(f\"Total examples: {len(train_data)}\")\n",
    "        \n",
    "        # Create output directories\n",
    "        ege_dir = processed_dir / \"ege_math\"\n",
    "        images_dir = ege_dir / \"images\"\n",
    "        student_answers_dir = images_dir / \"student_answers\"\n",
    "        problems_dir = images_dir / \"problems\"\n",
    "        correct_solutions_dir = images_dir / \"correct_solutions\"\n",
    "        \n",
    "        for dir_path in [ege_dir, student_answers_dir, problems_dir, correct_solutions_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process examples\n",
    "        processed_data = []\n",
    "        all_images_info = []\n",
    "        \n",
    "        image_type_mapping = {\n",
    "            'images_with_answer': (student_answers_dir, 'Student solution'),\n",
    "            'images_without_answer': (problems_dir, 'Problem statement'),\n",
    "            'images_with_true_solution': (correct_solutions_dir, 'Correct solution')\n",
    "        }\n",
    "        \n",
    "        for idx, item in enumerate(train_data):\n",
    "            if idx % 25 == 0:\n",
    "                print(f\"Processing example {idx + 1}/{len(train_data)}...\")\n",
    "            \n",
    "            # Create metadata entry\n",
    "            processed_item = {\n",
    "                'index': idx,\n",
    "                'solution_id': item.get('solution_id'),\n",
    "                'task_id': item.get('task_id'),\n",
    "                'example_id': item.get('example_id'),\n",
    "                'task_type': item.get('task_type'),\n",
    "                'score': item.get('score'),\n",
    "                'parts_count': item.get('parts_count'),\n",
    "                'dataset': 'ege_math',\n",
    "                'language': 'russian',\n",
    "                'problem': '',  # To be filled by OCR\n",
    "                'solution': '',  # To be filled by OCR\n",
    "                'student_answer': '',  # To be filled by OCR\n",
    "                'has_images': False,\n",
    "                'image_counts': {}\n",
    "            }\n",
    "            \n",
    "            # Process each image type\n",
    "            for field_name, (output_dir, description) in image_type_mapping.items():\n",
    "                images = item.get(field_name, [])\n",
    "                if images:\n",
    "                    processed_item['has_images'] = True\n",
    "                    processed_item['image_counts'][field_name] = len(images)\n",
    "                    \n",
    "                    # Save each image\n",
    "                    for img_idx, image_obj in enumerate(images):\n",
    "                        try:\n",
    "                            solution_id = item.get('solution_id', f'unknown_{idx}')\n",
    "                            image_filename = f\"ege_{solution_id}_{field_name}_{img_idx}.png\"\n",
    "                            image_path = output_dir / image_filename\n",
    "                            \n",
    "                            # Save PIL Image\n",
    "                            image_obj.save(image_path, 'PNG')\n",
    "                            \n",
    "                            # Track image info\n",
    "                            image_info = {\n",
    "                                'solution_id': solution_id,\n",
    "                                'task_type': item.get('task_type'),\n",
    "                                'score': item.get('score'),\n",
    "                                'image_filename': image_filename,\n",
    "                                'image_type': field_name,\n",
    "                                'image_description': description,\n",
    "                                'relative_path': f'images/{output_dir.name}/{image_filename}',\n",
    "                                'original_index': idx,\n",
    "                                'image_index': img_idx\n",
    "                            }\n",
    "                            all_images_info.append(image_info)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Failed to save {field_name} image {img_idx} for {solution_id}: {e}\")\n",
    "                else:\n",
    "                    processed_item['image_counts'][field_name] = 0\n",
    "            \n",
    "            processed_data.append(processed_item)\n",
    "        \n",
    "        # Save processed dataset\n",
    "        output_file = ege_dir / \"ege_processed.json\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Save image mapping\n",
    "        mapping_file = ege_dir / \"complete_image_mapping.json\"\n",
    "        with open(mapping_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_images_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Create statistics\n",
    "        stats = {\n",
    "            'total_examples': len(processed_data),\n",
    "            'total_images': len(all_images_info),\n",
    "            'image_type_counts': {}\n",
    "        }\n",
    "        \n",
    "        for field_name in image_type_mapping.keys():\n",
    "            count = len([img for img in all_images_info if img['image_type'] == field_name])\n",
    "            stats['image_type_counts'][field_name] = count\n",
    "        \n",
    "        # Create dataset info\n",
    "        dataset_info = {\n",
    "            \"dataset_name\": \"EGE Math Solutions Assessment Benchmark\",\n",
    "            \"source_url\": \"https://huggingface.co/datasets/Karifannaa/EGE_Math_Solutions_Assessment_Benchmark\",\n",
    "            \"paper_url\": \"https://arxiv.org/abs/2507.22958\",\n",
    "            \"description\": \"Russian high school math exam solutions with quality assessments and three types of images\",\n",
    "            \"language\": \"Russian\",\n",
    "            \"total_examples\": len(processed_data),\n",
    "            \"total_images\": len(all_images_info),\n",
    "            \"image_types\": {\n",
    "                \"images_with_answer\": \"Student handwritten solutions\",\n",
    "                \"images_without_answer\": \"Problem statements (no solutions shown)\",\n",
    "                \"images_with_true_solution\": \"Correct reference solutions\"\n",
    "            },\n",
    "            \"image_organization\": {\n",
    "                \"student_answers/\": \"Student solution images\",\n",
    "                \"problems/\": \"Problem statement images\",\n",
    "                \"correct_solutions/\": \"Reference solution images\"\n",
    "            },\n",
    "            \"format\": {\n",
    "                \"solution_id\": \"Unique solution identifier\",\n",
    "                \"task_type\": \"Mathematical topic/domain\",\n",
    "                \"score\": \"Quality assessment score (0-4)\",\n",
    "                \"image_counts\": \"Count of each image type for this example\"\n",
    "            },\n",
    "            \"use_cases\": [\n",
    "                \"Russian language math OCR testing\",\n",
    "                \"Cross-language error detection\",\n",
    "                \"Comparing student vs correct solutions\",\n",
    "                \"Problem statement extraction\"\n",
    "            ],\n",
    "            \"statistics\": stats\n",
    "        }\n",
    "        \n",
    "        with open(ege_dir / \"dataset_info.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nEGE Dataset download complete!\")\n",
    "        print(f\"Main data: {output_file}\")\n",
    "        print(f\"Total images: {len(all_images_info)}\")\n",
    "        print(f\"\\nImage breakdown:\")\n",
    "        for field_name, (_, description) in image_type_mapping.items():\n",
    "            count = stats['image_type_counts'][field_name]\n",
    "            print(f\"  {description}: {count} images\")\n",
    "        \n",
    "        return processed_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading EGE: {e}\")\n",
    "        return None\n",
    "\n",
    "# Download the dataset\n",
    "ege_data = download_ege_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Dataset Overview\n",
    "\n",
    "Let's summarize what we've downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def summarize_datasets():\n    \"\"\"Provide a summary of all downloaded datasets.\"\"\"\n    \n    print(\"DATASET DOWNLOAD SUMMARY\")\n    print(\"=\" * 50)\n    \n    datasets_info = [\n        {\n            'name': 'Math Misconceptions (MaE)',\n            'path': processed_dir / 'math_misconceptions' / 'math_misconceptions.json',\n            'language': 'English',\n            'content': '55 algebra misconceptions (220 examples)',\n            'use_case': 'Specific misconception testing'\n        },\n        {\n            'name': 'FERMAT',\n            'path': processed_dir / 'fermat' / 'fermat_processed.json',\n            'language': 'English',\n            'content': 'Handwritten math + images',\n            'use_case': 'OCR + error detection'\n        },\n        {\n            'name': 'EGE Math',\n            'path': processed_dir / 'ege_math' / 'ege_processed.json',\n            'language': 'Russian',\n            'content': 'EGE exam solutions + 3 image types',\n            'use_case': 'Cross-language detection'\n        }\n    ]\n    \n    for dataset in datasets_info:\n        if dataset['path'].exists():\n            try:\n                with open(dataset['path'], 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                    count = len(data)\n                    status = f\"Downloaded: {count} examples\"\n            except:\n                status = \"File exists but couldn't read\"\n        else:\n            status = \"Not downloaded\"\n        \n        print(f\"\\n{dataset['name']}\")\n        print(f\"   Language: {dataset['language']}\")\n        print(f\"   Content: {dataset['content']}\")\n        print(f\"   Use Case: {dataset['use_case']}\")\n        print(f\"   Status: {status}\")\n    \n    print(f\"\\nAll datasets saved to: {base_dir.absolute()}\")\n    \n    # Show directory structure\n    print(f\"\\nDirectory Structure:\")\n    print(f\"{base_dir}/\")\n    print(f\"└── processed/\")\n    for dataset_dir in processed_dir.iterdir():\n        if dataset_dir.is_dir():\n            print(f\"    ├── {dataset_dir.name}/\")\n            for file in dataset_dir.iterdir():\n                if file.is_file():\n                    print(f\"    │   ├── {file.name}\")\n                elif file.is_dir():\n                    print(f\"    │   └── {file.name}/ (images)\")\n\n# Show summary\nsummarize_datasets()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Next Steps\n\n## Using the Datasets\n\n1. **Math Misconceptions**: Use for testing error detection algorithms on common student mistakes\n2. **FERMAT**: Use for testing OCR + error detection on handwritten math images\n3. **EGE Math**: Use for cross-language research and comparing different image types\n\n## Integration with Error Detection Tools\n\nThese datasets can be integrated with:\n- OCR systems (Mathpix, GPT-4V)\n- Error detection models\n- Math education research tools\n\n## File Organization\n\nEach dataset includes:\n- **Main data file**: JSON with all examples\n- **dataset_info.json**: Complete metadata and documentation\n- **Images folder**: Organized image files (where applicable)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}