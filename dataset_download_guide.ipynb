{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Error Detection Datasets - Download Guide\n",
    "\n",
    "This notebook provides step-by-step instructions for downloading and setting up three key datasets for math error detection research:\n",
    "\n",
    "1. **Math Misconceptions Dataset** - 220 algebra misconception examples\n",
    "2. **FERMAT Dataset** - 2,244 handwritten math problems with images\n",
    "3. **EGE Math Dataset** - 122 Russian EGE exam solutions with 3 image types\n",
    "\n",
    "Each dataset is useful for different aspects of math error detection and OCR research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install datasets requests pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Directory Structure\n",
    "\n",
    "Create organized folder structure for all datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure\n",
    "base_dir = Path(\"math_datasets\")\n",
    "processed_dir = base_dir / \"processed\"\n",
    "raw_dir = base_dir / \"raw\"\n",
    "scripts_dir = base_dir / \"scripts\"\n",
    "\n",
    "# Create all directories\n",
    "for dir_path in [processed_dir, raw_dir, scripts_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Created directory structure:\")\n",
    "print(f\"{base_dir}/\")\n",
    "print(f\"├── processed/    # Clean, ready-to-use datasets\")\n",
    "print(f\"├── raw/          # Original downloaded data\")\n",
    "print(f\"└── scripts/      # Processing utilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1: Math Misconceptions Dataset\n",
    "\n",
    "**Source**: [MarkingCopilot Research Benchmarks](https://github.com/MarkingCopilot/markingResearch/blob/main/docs/benchmarks.md)  \n",
    "**Size**: 220 examples  \n",
    "**Language**: English  \n",
    "**Content**: Common algebra misconceptions with incorrect/correct answer pairs  \n",
    "**Use Cases**: Testing error detection on student misconceptions\n",
    "\n",
    "## Download Math Misconceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_math_misconceptions():\n",
    "    \"\"\"Download math misconceptions dataset from the benchmarks repository.\"\"\"\n",
    "    \n",
    "    print(\"Downloading Math Misconceptions Dataset...\")\n",
    "    \n",
    "    # URL to the math misconceptions data\n",
    "    # Note: This would need to be replaced with the actual URL when available\n",
    "    misconceptions_url = \"https://raw.githubusercontent.com/MarkingCopilot/markingResearch/main/data/math_misconceptions.json\"\n",
    "    \n",
    "    try:\n",
    "        # For demonstration - create sample data structure\n",
    "        # In practice, you would download from the actual URL\n",
    "        sample_misconceptions = [\n",
    "            {\n",
    "                \"Example Number\": 1,\n",
    "                \"Question\": \"Solve for x: 2x + 3 = 7\",\n",
    "                \"Incorrect Answer\": \"x = 5\",\n",
    "                \"Correct Answer\": \"x = 2\",\n",
    "                \"Misconception\": \"Adding instead of subtracting when isolating variable\",\n",
    "                \"Misconception ID\": \"ISOL_ADD_INSTEAD_SUB\",\n",
    "                \"Topic\": \"Linear equations\"\n",
    "            },\n",
    "            # Add more examples here...\n",
    "        ]\n",
    "        \n",
    "        # Create output directories\n",
    "        misconceptions_dir = processed_dir / \"math_misconceptions\"\n",
    "        misconceptions_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save the dataset\n",
    "        output_file = misconceptions_dir / \"math_misconceptions.json\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(sample_misconceptions, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Create dataset info\n",
    "        dataset_info = {\n",
    "            \"dataset_name\": \"Math Misconceptions Dataset\",\n",
    "            \"source_url\": \"https://github.com/MarkingCopilot/markingResearch/blob/main/docs/benchmarks.md\",\n",
    "            \"description\": \"Collection of common algebra misconceptions with structured incorrect/correct answer pairs\",\n",
    "            \"language\": \"English\",\n",
    "            \"total_examples\": len(sample_misconceptions),\n",
    "            \"format\": {\n",
    "                \"Question\": \"Problem statement\",\n",
    "                \"Incorrect Answer\": \"Common student mistake\",\n",
    "                \"Correct Answer\": \"Expected correct response\",\n",
    "                \"Misconception\": \"Description of the underlying misconception\",\n",
    "                \"Misconception ID\": \"Unique identifier for misconception type\",\n",
    "                \"Topic\": \"Mathematical topic area\"\n",
    "            },\n",
    "            \"use_cases\": [\n",
    "                \"Testing error detection algorithms\",\n",
    "                \"Understanding common student mistakes\",\n",
    "                \"Training misconception identification models\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(misconceptions_dir / \"dataset_info.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Math Misconceptions downloaded: {len(sample_misconceptions)} examples\")\n",
    "        print(f\"Saved to: {output_file}\")\n",
    "        \n",
    "        return sample_misconceptions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading misconceptions: {e}\")\n",
    "        return None\n",
    "\n",
    "# Download the dataset\n",
    "misconceptions_data = download_math_misconceptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2: FERMAT Dataset\n",
    "\n",
    "**Source**: [HuggingFace - ai4bharat/fermat](https://huggingface.co/datasets/ai4bharat/fermat)  \n",
    "**Paper**: \"Can Vision-Language Models Evaluate Handwritten Math?\" (arXiv:2501.07244)  \n",
    "**Size**: 2,244 handwritten math problems  \n",
    "**Language**: English  \n",
    "**Content**: Handwritten math solutions with error annotations and images  \n",
    "**Use Cases**: Testing complete OCR + error detection pipeline\n",
    "\n",
    "## Download FERMAT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_fermat_dataset(sample_size=100, save_images=True):\n",
    "    \"\"\"Download FERMAT dataset from HuggingFace.\n",
    "    \n",
    "    Args:\n",
    "        sample_size: Number of examples to process (default 100, set to None for all 2244)\n",
    "        save_images: Whether to save the handwritten images\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Downloading FERMAT Dataset (sample_size: {sample_size})...\")\n",
    "    \n",
    "    try:\n",
    "        # Load dataset from HuggingFace\n",
    "        print(\"Loading from HuggingFace...\")\n",
    "        dataset = load_dataset(\"ai4bharat/fermat\")\n",
    "        train_data = dataset['train']\n",
    "        \n",
    "        print(f\"Total examples available: {len(train_data)}\")\n",
    "        \n",
    "        # Create output directories\n",
    "        fermat_dir = processed_dir / \"fermat\"\n",
    "        fermat_images_dir = fermat_dir / \"images\"\n",
    "        fermat_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        if save_images:\n",
    "            fermat_images_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Process examples\n",
    "        processed_data = []\n",
    "        num_to_process = sample_size if sample_size else len(train_data)\n",
    "        \n",
    "        for idx in range(min(num_to_process, len(train_data))):\n",
    "            item = train_data[idx]\n",
    "            \n",
    "            if idx % 50 == 0:\n",
    "                print(f\"Processing example {idx + 1}/{num_to_process}...\")\n",
    "            \n",
    "            # Extract metadata\n",
    "            processed_item = {\n",
    "                'index': idx,\n",
    "                'problem': item.get('problem', ''),\n",
    "                'correct_answer': item.get('correct_answer', ''),\n",
    "                'student_answer': item.get('student_answer', ''),\n",
    "                'has_error': item.get('has_error', False),\n",
    "                'error_reasoning': item.get('error_reasoning', ''),\n",
    "                'domain': item.get('domain', ''),\n",
    "                'grade': item.get('grade', ''),\n",
    "                'handwriting_legible': item.get('handwriting_legible', True),\n",
    "                'good_image_quality': item.get('good_image_quality', True),\n",
    "                'dataset': 'fermat',\n",
    "                'language': 'english'\n",
    "            }\n",
    "            \n",
    "            # Handle image\n",
    "            if save_images and 'image' in item and item['image']:\n",
    "                image_filename = f\"fermat_{idx:04d}.png\"\n",
    "                image_path = fermat_images_dir / image_filename\n",
    "                \n",
    "                try:\n",
    "                    # Save PIL Image\n",
    "                    item['image'].save(image_path, 'PNG')\n",
    "                    processed_item['image_filename'] = image_filename\n",
    "                    processed_item['has_image'] = True\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to save image {idx}: {e}\")\n",
    "                    processed_item['has_image'] = False\n",
    "            else:\n",
    "                processed_item['has_image'] = False\n",
    "            \n",
    "            processed_data.append(processed_item)\n",
    "        \n",
    "        # Save processed dataset\n",
    "        output_file = fermat_dir / \"fermat_processed.json\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Create dataset info\n",
    "        error_count = sum(1 for item in processed_data if item.get('has_error', False))\n",
    "        domains = Counter([item.get('domain', 'unknown') for item in processed_data])\n",
    "        \n",
    "        dataset_info = {\n",
    "            \"dataset_name\": \"FERMAT: Can Vision-Language Models Evaluate Handwritten Math?\",\n",
    "            \"source_url\": \"https://huggingface.co/datasets/ai4bharat/fermat\",\n",
    "            \"paper_url\": \"https://arxiv.org/abs/2501.07244\",\n",
    "            \"description\": \"Benchmark for assessing VLMs' ability to detect, localize and correct errors in handwritten mathematical content\",\n",
    "            \"language\": \"English\",\n",
    "            \"total_examples_available\": len(train_data),\n",
    "            \"processed_examples\": len(processed_data),\n",
    "            \"examples_with_errors\": error_count,\n",
    "            \"examples_without_errors\": len(processed_data) - error_count,\n",
    "            \"domains\": dict(domains.most_common()),\n",
    "            \"format\": {\n",
    "                \"problem\": \"Original math question in LaTeX\",\n",
    "                \"correct_answer\": \"Correct solution in LaTeX\",\n",
    "                \"student_answer\": \"Erroneous solution in LaTeX\",\n",
    "                \"has_error\": \"Boolean indicating actual error vs superficial change\",\n",
    "                \"error_reasoning\": \"Explanation of introduced error\",\n",
    "                \"domain\": \"Mathematical domain code\",\n",
    "                \"grade\": \"Grade level\",\n",
    "                \"image_filename\": \"Corresponding handwritten image file\"\n",
    "            },\n",
    "            \"use_cases\": [\n",
    "                \"Testing OCR accuracy on handwritten math\",\n",
    "                \"Evaluating VLM error detection capabilities\",\n",
    "                \"Training handwritten math recognition models\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(fermat_dir / \"dataset_info.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"FERMAT downloaded: {len(processed_data)} examples\")\n",
    "        print(f\"Saved to: {output_file}\")\n",
    "        if save_images:\n",
    "            image_count = sum(1 for item in processed_data if item.get('has_image', False))\n",
    "            print(f\"Images saved: {image_count} in {fermat_images_dir}\")\n",
    "        \n",
    "        return processed_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading FERMAT: {e}\")\n",
    "        return None\n",
    "\n",
    "# Download the dataset (start with smaller sample)\n",
    "fermat_data = download_fermat_dataset(sample_size=100, save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase FERMAT Sample Size (Optional)\n",
    "\n",
    "If you want to download more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download more examples (this may take longer)\n",
    "# fermat_data_large = download_fermat_dataset(sample_size=500, save_images=True)\n",
    "\n",
    "# Uncomment to download ALL examples (this will take significant time and space)\n",
    "# fermat_data_full = download_fermat_dataset(sample_size=None, save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 3: EGE Math Solutions Assessment Benchmark\n",
    "\n",
    "**Source**: [HuggingFace - Karifannaa/EGE_Math_Solutions_Assessment_Benchmark](https://huggingface.co/datasets/Karifannaa/EGE_Math_Solutions_Assessment_Benchmark)  \n",
    "**Paper**: \"EGE Math Solutions Assessment Benchmark\" (arXiv:2507.22958)  \n",
    "**Size**: 122 examples  \n",
    "**Language**: Russian  \n",
    "**Content**: Russian EGE exam solutions with 3 types of images  \n",
    "**Use Cases**: Cross-language error detection, Russian math education research\n",
    "\n",
    "## Download EGE Dataset with All Image Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ege_dataset():\n",
    "    \"\"\"Download EGE Math dataset with all three image types.\"\"\"\n",
    "    \n",
    "    print(\"Downloading EGE Math Dataset...\")\n",
    "    print(\"This dataset contains THREE types of images:\")\n",
    "    print(\"1. images_with_answer (student solutions)\")\n",
    "    print(\"2. images_without_answer (problem statements)\")\n",
    "    print(\"3. images_with_true_solution (correct solutions)\")\n",
    "    \n",
    "    try:\n",
    "        # Load dataset from HuggingFace\n",
    "        dataset = load_dataset(\"Karifannaa/EGE_Math_Solutions_Assessment_Benchmark\")\n",
    "        train_data = dataset['train']\n",
    "        \n",
    "        print(f\"Total examples: {len(train_data)}\")\n",
    "        \n",
    "        # Create output directories\n",
    "        ege_dir = processed_dir / \"ege_math\"\n",
    "        images_dir = ege_dir / \"images\"\n",
    "        student_answers_dir = images_dir / \"student_answers\"\n",
    "        problems_dir = images_dir / \"problems\"\n",
    "        correct_solutions_dir = images_dir / \"correct_solutions\"\n",
    "        \n",
    "        for dir_path in [ege_dir, student_answers_dir, problems_dir, correct_solutions_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process examples\n",
    "        processed_data = []\n",
    "        all_images_info = []\n",
    "        \n",
    "        image_type_mapping = {\n",
    "            'images_with_answer': (student_answers_dir, 'Student solution'),\n",
    "            'images_without_answer': (problems_dir, 'Problem statement'),\n",
    "            'images_with_true_solution': (correct_solutions_dir, 'Correct solution')\n",
    "        }\n",
    "        \n",
    "        for idx, item in enumerate(train_data):\n",
    "            if idx % 25 == 0:\n",
    "                print(f\"Processing example {idx + 1}/{len(train_data)}...\")\n",
    "            \n",
    "            # Create metadata entry\n",
    "            processed_item = {\n",
    "                'index': idx,\n",
    "                'solution_id': item.get('solution_id'),\n",
    "                'task_id': item.get('task_id'),\n",
    "                'example_id': item.get('example_id'),\n",
    "                'task_type': item.get('task_type'),\n",
    "                'score': item.get('score'),\n",
    "                'parts_count': item.get('parts_count'),\n",
    "                'dataset': 'ege_math',\n",
    "                'language': 'russian',\n",
    "                'problem': '',  # To be filled by OCR\n",
    "                'solution': '',  # To be filled by OCR\n",
    "                'student_answer': '',  # To be filled by OCR\n",
    "                'has_images': False,\n",
    "                'image_counts': {}\n",
    "            }\n",
    "            \n",
    "            # Process each image type\n",
    "            for field_name, (output_dir, description) in image_type_mapping.items():\n",
    "                images = item.get(field_name, [])\n",
    "                if images:\n",
    "                    processed_item['has_images'] = True\n",
    "                    processed_item['image_counts'][field_name] = len(images)\n",
    "                    \n",
    "                    # Save each image\n",
    "                    for img_idx, image_obj in enumerate(images):\n",
    "                        try:\n",
    "                            solution_id = item.get('solution_id', f'unknown_{idx}')\n",
    "                            image_filename = f\"ege_{solution_id}_{field_name}_{img_idx}.png\"\n",
    "                            image_path = output_dir / image_filename\n",
    "                            \n",
    "                            # Save PIL Image\n",
    "                            image_obj.save(image_path, 'PNG')\n",
    "                            \n",
    "                            # Track image info\n",
    "                            image_info = {\n",
    "                                'solution_id': solution_id,\n",
    "                                'task_type': item.get('task_type'),\n",
    "                                'score': item.get('score'),\n",
    "                                'image_filename': image_filename,\n",
    "                                'image_type': field_name,\n",
    "                                'image_description': description,\n",
    "                                'relative_path': f'images/{output_dir.name}/{image_filename}',\n",
    "                                'original_index': idx,\n",
    "                                'image_index': img_idx\n",
    "                            }\n",
    "                            all_images_info.append(image_info)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Failed to save {field_name} image {img_idx} for {solution_id}: {e}\")\n",
    "                else:\n",
    "                    processed_item['image_counts'][field_name] = 0\n",
    "            \n",
    "            processed_data.append(processed_item)\n",
    "        \n",
    "        # Save processed dataset\n",
    "        output_file = ege_dir / \"ege_processed.json\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(processed_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Save image mapping\n",
    "        mapping_file = ege_dir / \"complete_image_mapping.json\"\n",
    "        with open(mapping_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_images_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Create statistics\n",
    "        stats = {\n",
    "            'total_examples': len(processed_data),\n",
    "            'total_images': len(all_images_info),\n",
    "            'image_type_counts': {}\n",
    "        }\n",
    "        \n",
    "        for field_name in image_type_mapping.keys():\n",
    "            count = len([img for img in all_images_info if img['image_type'] == field_name])\n",
    "            stats['image_type_counts'][field_name] = count\n",
    "        \n",
    "        # Create dataset info\n",
    "        dataset_info = {\n",
    "            \"dataset_name\": \"EGE Math Solutions Assessment Benchmark\",\n",
    "            \"source_url\": \"https://huggingface.co/datasets/Karifannaa/EGE_Math_Solutions_Assessment_Benchmark\",\n",
    "            \"paper_url\": \"https://arxiv.org/abs/2507.22958\",\n",
    "            \"description\": \"Russian high school math exam solutions with quality assessments and three types of images\",\n",
    "            \"language\": \"Russian\",\n",
    "            \"total_examples\": len(processed_data),\n",
    "            \"total_images\": len(all_images_info),\n",
    "            \"image_types\": {\n",
    "                \"images_with_answer\": \"Student handwritten solutions\",\n",
    "                \"images_without_answer\": \"Problem statements (no solutions shown)\",\n",
    "                \"images_with_true_solution\": \"Correct reference solutions\"\n",
    "            },\n",
    "            \"image_organization\": {\n",
    "                \"student_answers/\": \"Student solution images\",\n",
    "                \"problems/\": \"Problem statement images\",\n",
    "                \"correct_solutions/\": \"Reference solution images\"\n",
    "            },\n",
    "            \"format\": {\n",
    "                \"solution_id\": \"Unique solution identifier\",\n",
    "                \"task_type\": \"Mathematical topic/domain\",\n",
    "                \"score\": \"Quality assessment score (0-4)\",\n",
    "                \"image_counts\": \"Count of each image type for this example\"\n",
    "            },\n",
    "            \"use_cases\": [\n",
    "                \"Russian language math OCR testing\",\n",
    "                \"Cross-language error detection\",\n",
    "                \"Comparing student vs correct solutions\",\n",
    "                \"Problem statement extraction\"\n",
    "            ],\n",
    "            \"statistics\": stats\n",
    "        }\n",
    "        \n",
    "        with open(ege_dir / \"dataset_info.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nEGE Dataset download complete!\")\n",
    "        print(f\"Main data: {output_file}\")\n",
    "        print(f\"Total images: {len(all_images_info)}\")\n",
    "        print(f\"\\nImage breakdown:\")\n",
    "        for field_name, (_, description) in image_type_mapping.items():\n",
    "            count = stats['image_type_counts'][field_name]\n",
    "            print(f\"  {description}: {count} images\")\n",
    "        \n",
    "        return processed_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading EGE: {e}\")\n",
    "        return None\n",
    "\n",
    "# Download the dataset\n",
    "ege_data = download_ege_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Dataset Overview\n",
    "\n",
    "Let's summarize what we've downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_datasets():\n",
    "    \"\"\"Provide a summary of all downloaded datasets.\"\"\"\n",
    "    \n",
    "    print(\"DATASET DOWNLOAD SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    datasets_info = [\n",
    "        {\n",
    "            'name': 'Math Misconceptions',\n",
    "            'path': processed_dir / 'math_misconceptions' / 'math_misconceptions.json',\n",
    "            'language': 'English',\n",
    "            'content': 'Algebra misconceptions',\n",
    "            'use_case': 'Error detection testing'\n",
    "        },\n",
    "        {\n",
    "            'name': 'FERMAT',\n",
    "            'path': processed_dir / 'fermat' / 'fermat_processed.json',\n",
    "            'language': 'English',\n",
    "            'content': 'Handwritten math + images',\n",
    "            'use_case': 'OCR + error detection'\n",
    "        },\n",
    "        {\n",
    "            'name': 'EGE Math',\n",
    "            'path': processed_dir / 'ege_math' / 'ege_processed.json',\n",
    "            'language': 'Russian',\n",
    "            'content': 'EGE exam solutions + 3 image types',\n",
    "            'use_case': 'Cross-language detection'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for dataset in datasets_info:\n",
    "        if dataset['path'].exists():\n",
    "            try:\n",
    "                with open(dataset['path'], 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    count = len(data)\n",
    "                    status = f\"Downloaded: {count} examples\"\n",
    "            except:\n",
    "                status = \"File exists but couldn't read\"\n",
    "        else:\n",
    "            status = \"Not downloaded\"\n",
    "        \n",
    "        print(f\"\\n{dataset['name']}\")\n",
    "        print(f\"   Language: {dataset['language']}\")\n",
    "        print(f\"   Content: {dataset['content']}\")\n",
    "        print(f\"   Use Case: {dataset['use_case']}\")\n",
    "        print(f\"   Status: {status}\")\n",
    "    \n",
    "    print(f\"\\nAll datasets saved to: {base_dir.absolute()}\")\n",
    "    \n",
    "    # Show directory structure\n",
    "    print(f\"\\nDirectory Structure:\")\n",
    "    print(f\"{base_dir}/\")\n",
    "    print(f\"├── processed/\")\n",
    "    for dataset_dir in processed_dir.iterdir():\n",
    "        if dataset_dir.is_dir():\n",
    "            print(f\"│   ├── {dataset_dir.name}/\")\n",
    "            for file in dataset_dir.iterdir():\n",
    "                if file.is_file():\n",
    "                    print(f\"│   │   ├── {file.name}\")\n",
    "                elif file.is_dir():\n",
    "                    print(f\"│   │   └── {file.name}/ (images)\")\n",
    "    print(f\"├── raw/\")\n",
    "    print(f\"└── scripts/\")\n",
    "\n",
    "# Show summary\n",
    "summarize_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "## Using the Datasets\n",
    "\n",
    "1. **Math Misconceptions**: Use for testing error detection algorithms on common student mistakes\n",
    "2. **FERMAT**: Use for testing OCR + error detection on handwritten math images\n",
    "3. **EGE Math**: Use for cross-language research and comparing different image types\n",
    "\n",
    "## Integration with Error Detection Tools\n",
    "\n",
    "These datasets can be integrated with:\n",
    "- OCR systems (Mathpix, GPT-4V)\n",
    "- Error detection models\n",
    "- Math education research tools\n",
    "\n",
    "## File Organization\n",
    "\n",
    "Each dataset includes:\n",
    "- **Main data file**: JSON with all examples\n",
    "- **dataset_info.json**: Complete metadata and documentation\n",
    "- **Images folder**: Organized image files (where applicable)\n",
    "\n",
    "## Contributing Back\n",
    "\n",
    "Consider contributing:\n",
    "- Improved processing scripts\n",
    "- Additional dataset formats\n",
    "- Error detection results and benchmarks\n",
    "\n",
    "## Repository Integration\n",
    "\n",
    "This notebook can be added to the [MarkingCopilot/trainingData](https://github.com/MarkingCopilot/trainingData) repository to help others download and set up these datasets for math error detection research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}